<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>HausaNLP Research Group</title>
    <link>https://hausanlp.github.io/</link>
      <atom:link href="https://hausanlp.github.io/index.xml" rel="self" type="application/rss+xml" />
    <description>HausaNLP Research Group</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>© HausaNLP Research Group. Site maintained by Shamsuddeen Muhammad</copyright><lastBuildDate>Mon, 10 Jul 2023 18:13:04 +0000</lastBuildDate>
    <image>
      <url>https://hausanlp.github.io/images/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url>
      <title>HausaNLP Research Group</title>
      <link>https://hausanlp.github.io/</link>
    </image>
    
    <item>
      <title>HausaNLP at SemEval-2023 Task 10: Transfer Learning, Synthetic Data and Side-information for Multi-level Sexism Classification</title>
      <link>https://hausanlp.github.io/publication/hausanlp-semeval-2023/</link>
      <pubDate>Mon, 10 Jul 2023 18:13:04 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/hausanlp-semeval-2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HaVQA: A Dataset for Visual Question Answering and Multimodal Research in Hausa Language</title>
      <link>https://hausanlp.github.io/publication/havqa-2023/</link>
      <pubDate>Mon, 10 Jul 2023 18:13:04 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/havqa-2023/</guid>
      <description></description>
    </item>
    
    <item>
      <title>SemEval 2023 Task 12: Sentiment Analysis for African Languages (AfriSenti-SemEval)</title>
      <link>https://hausanlp.github.io/publication/muhammad-etal-2023-semeval/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/muhammad-etal-2023-semeval/</guid>
      <description></description>
    </item>
    
    <item>
      <title>AfriSenti: A Twitter Sentiment Analysis Benchmark for African Languages</title>
      <link>https://hausanlp.github.io/publication/https-doi-org-10-48550-arxiv-2302-08956/</link>
      <pubDate>Sun, 01 Jan 2023 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/https-doi-org-10-48550-arxiv-2302-08956/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HERDPhobia: A Dataset for Hate Speech Detection against Fulani Herdsmen in Nigeria</title>
      <link>https://hausanlp.github.io/publication/aliyu-2022-herdphobia/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/aliyu-2022-herdphobia/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Separating Grains from the Chaff: Using Data Filtering to Improve Multilingual Translation for Low-Resourced African Languages</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-et-al-2022-wmt/</link>
      <pubDate>Thu, 01 Dec 2022 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-et-al-2022-wmt/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hausa Visual Genome: A Dataset for Multi-Modal English to Hausa Machine Translation</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-et-al-2022-lrec/</link>
      <pubDate>Wed, 01 Jun 2022 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-et-al-2022-lrec/</guid>
      <description></description>
    </item>
    
    <item>
      <title>NaijaSenti: A Nigerian Twitter Sentiment Corpus for Multilingual Sentiment Analysis</title>
      <link>https://hausanlp.github.io/publication/muhammad-2022-naijasenti/</link>
      <pubDate>Sat, 01 Jan 2022 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/muhammad-2022-naijasenti/</guid>
      <description></description>
    </item>
    
    <item>
      <title>HausaNLP Research Group got funding from Lacuna Fund.</title>
      <link>https://hausanlp.github.io/post/hausanlp-lacuna-grant/</link>
      <pubDate>Sun, 17 Oct 2021 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/post/hausanlp-lacuna-grant/</guid>
      <description>
&lt;script src=&#34;https://hausanlp.github.io/post/hausanlp-lacuna-grant/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;p&gt;The HausaNLP proposal called SentiNaija is one of the selected projects in the &lt;a href=&#34;https://lacunafund.org/language-2020-awards/&#34;&gt;Lacuna Language 2020 Awards&lt;/a&gt;, an action promoted by Lacuna Fund, the first collaborative initiative in the world dedicated to providing the resources that data scientists, researchers, and social entrepreneurs need to produce labelled datasets in order to address the main issues within their communities.&lt;/p&gt;
&lt;p&gt;The main goal of the project is to promote global digital inclusion by producing the first high-quality open datasets with manual annotations, gathered from content included on digital platforms and written in the three main Nigerian languages: Hausa, Igbo, Yoruba, and Pidgin. These datasets are important for natural language processing tasks such as sentiment and emotion analysis, as well as the detection of hate speech and fake news.&lt;/p&gt;
&lt;p&gt;Languages spoken in Africa have few language resources, and those that do exist are insufficient, e.g., datasets for important artificial intelligence (AI) tasks. This project will play a key role in the development of information for African languages, encouraging the growth and dissemination of AI research in these locations and benefiting from these datasets.Find out more about the project &lt;a href=&#34;https://github.com/hausanlp/sentiNaija&#34;&gt;on the preject Github page&lt;/a&gt;&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
</description>
    </item>
    
    <item>
      <title>Development of Nigerian Twitter Sentiment Corpus</title>
      <link>https://hausanlp.github.io/project/sanalysis/</link>
      <pubDate>Tue, 27 Apr 2021 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/sanalysis/</guid>
      <description>&lt;p&gt;NaijaSenti is a &lt;a href=&#34;https://lacunafund.org/language-2020-awards/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Lacuna funded&lt;/a&gt; project for the developement of sentiment corpus for four Nigerain languages (Hausa, Igbo, Yoruba and Pidgin). Visit the project Github page for more information &lt;a href=&#34;https://github.com/hausanlp/NaijaSenti&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&#34;style&#34;&gt;&lt;style&gt;&lt;/h1&gt;
&lt;h1 id=&#34;body-&#34;&gt;body {&lt;/h1&gt;
&lt;h1 id=&#34;text-align-justify&#34;&gt;text-align: justify}&lt;/h1&gt;
&lt;h1 id=&#34;style-1&#34;&gt;&lt;/style&gt;&lt;/h1&gt;
</description>
    </item>
    
    <item>
      <title>Sentiment Corpus Generation in Low Resource Language A bumpy Journey</title>
      <link>https://hausanlp.github.io/post/building_sentiment_corpus/</link>
      <pubDate>Mon, 18 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/post/building_sentiment_corpus/</guid>
      <description>
&lt;script src=&#34;https://hausanlp.github.io/post/building_sentiment_corpus/index_files/header-attrs/header-attrs.js&#34;&gt;&lt;/script&gt;


&lt;div id=&#34;introduction&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Sentiment analysis (SA) is one of the most trending research areas in Artificial Intelligence (AI). Sentiment analysis is a technique used to identify the sentiments contained in natural language, which is mostly shared on social media platforms. A lot has been achieved in sentiment analysis research, focusing mostly on Rich-Resource Languages like English, German, and Arabic. However, there is little research on many Low Resources Languages. Consequently, we embarked on a mission to promote research on SA in languages spoken in Nigeria, which are all low resources languages. Our research was found worthy by Lacuna Fund, and they supported our team to develop sentiment corpus, sentiment lexicon, and hate speech lexicon for Hausa, Yoruba, and Igbo languages. These are important resources required in sentiment analysis in any language. The project is ongoing, notwithstanding, this article summarizes some of the challenges we faced in the study.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;data-acquisition&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data Acquisition&lt;/h2&gt;
&lt;p&gt;In sentiment analysis, extracting data is very crucial and is often considered as one of the least challenging stage. This is because there are several tools, packages, and libraries to extract and preprocess the data from social media platforms like Twitter and Facebook. However, that’s not the case in many low resource languages.
The first challenge we faced in data extraction is, Twitter does not have language codes for Hausa, Yoruba, and Igbo and so,[d] extraction tweets in these languages based on language code is impossible. Again, the location code can also not be used because multiple languages are used all over the country. Consequently, we had to crawl the tweets using distant supervision and via the use of stop words. The stop word list is also not available in the languages, we had to devise a methodology, and generated stop words for the languages.
Despite all the above, a lot of preprocessing was done to filter out tweets that are not in the target languages. In conclusion, data extraction in low resource languages is possible despite insufficiency of standard methods for the extraction. Each language is unique and appropriate methods should be devised to fit the purpose.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;annotation-tools&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Annotation Tools&lt;/h2&gt;
&lt;p&gt;Annotating text means adding meta-data to text, like semantics or sentiments. A good way for the AI to learn and understand nuances is through human annotations. Annotation is used to create datasets for natural language processing. The texts are either annotated or labeled with the purpose to mak the keywords or important words comprehensible to machines, and helping them to respond in the same way. We can either annotate an entire body of text into a class, called classification or annotate a specific word (s) called tagging.
Text annotation can easily be done in spreadsheet software like MS Excel; however, the process becomes tedious when the amount of data to annotate is large. Other limitations are spreadsheets are not convenient for multiuser annotation or calculating Inter Annotator Agreement (IAA). Consequently, it is more efficient to use specialized tools for the text annotation. However, most of the tools available (both free and paid) are in the development stage with obvious bugs. We tried over five tools and all of them have one problem or the other. The tool that we finally settled on comes near to perfection, but the review option is not working, and so the annotation texts cannot be reviewed in the tool.
The challenge of choosing an annotation tool came as a shock to us, because during our preliminary study, we saw a lot of good options but upon using the tools, we found out that most of the developers are over-selling the capabilities of their tools. In conclusion, when choosing an annotation tool, it’s good to thoroughly explore the tool and try their functionality early to see if they fit your use-case.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;annotation-guideline-and-annotation-training&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Annotation Guideline and Annotation Training&lt;/h2&gt;
&lt;p&gt;Annotation is mostly done by multiple annotators, preparable odd numbers, typically three to five in number. Therefore, it is crucial to develop an annotation guideline to aid the annotators. An effective annotation guideline helps annotators to understand clearly what is expected of them and have accurate annotation. In rich resource languages, this stage is fairly straightforward. There are several annotation guidelines available in the literature and research are quite familiar with annotation in the languages. However, because of the peculiarities of each language, the existing annotation guidelines will not serve the purpose. Additionally, due to the insufficiency of researchers working on low resource languages, getting annotators that can accurately annotate texts in low resource languages is quite difficult. Several rounds of training and retraining is required to prepare the annotators and ensure a high inter annotator agreement.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;There are several potentials and benefits to sentiment analysis research in low resource languages. Despite the several challenges, these challenges are opportunities for novel studies.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>An Enhanced Feature Acquisition for Sentiment Analysis of English and Hausa Tweets</title>
      <link>https://hausanlp.github.io/publication/abubakar-2021/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abubakar-2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Weekly Meeting</title>
      <link>https://hausanlp.github.io/event/example/</link>
      <pubDate>Sun, 27 Dec 2020 09:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/event/example/</guid>
      <description>&lt;!---
#Slides can be added in a few ways:

#- **Create** slides using Wowchemy&#39;s #[*Slides*](https://wowchemy.com/docs/managing-content/#create-sli#des) feature and link using `slides` parameter in the front #matter of the talk file
#- **Upload** an existing slide deck to `static/` and link using #`url_slides` parameter in the front matter of the talk file
#- **Embed** your slides (e.g. Google Slides) or presentation #video on this page using #[shortcodes](https://wowchemy.com/docs/writing-markdown-latex/).

#Further event details, including page elements such as image #galleries, can be added to the body of this page.
--&gt;</description>
    </item>
    
    <item>
      <title>Using Self-Training to Improve Back-Translation in Low Resource Neural Machine Translation</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-2020-aa/</link>
      <pubDate>Mon, 01 Jun 2020 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-2020-aa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Participatory Research for Low-resourced Machine Translation: A Case Study in African Languages</title>
      <link>https://hausanlp.github.io/publication/nekoto-2020-participatory/</link>
      <pubDate>Wed, 01 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/nekoto-2020-participatory/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hausa WordNet: An Electronic Lexical Resource</title>
      <link>https://hausanlp.github.io/publication/amina2021/</link>
      <pubDate>Thu, 07 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/amina2021/</guid>
      <description></description>
    </item>
    
    <item>
      <title>hauWE: Hausa Words Embedding for Natural Language Processing</title>
      <link>https://hausanlp.github.io/publication/abdulmumin-2019-aa/</link>
      <pubDate>Fri, 01 Nov 2019 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/abdulmumin-2019-aa/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Hausa Multimodal Machine Translation</title>
      <link>https://hausanlp.github.io/project/hausatranslation/</link>
      <pubDate>Wed, 27 Apr 2016 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/project/hausatranslation/</guid>
      <description>&lt;p&gt;For more information about this project, visit the project &lt;a href=&#34;https://github.com/hausanlp/HausaVisualGenome&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github page&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Text normalization algorithm for facebook chats in hausa language</title>
      <link>https://hausanlp.github.io/publication/maitama-2014-text/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/publication/maitama-2014-text/</guid>
      <description>&lt;p&gt;The rapid increase in using non-standard words (NSWs) in communication through the social media is causing difficulties in understanding contents of the text messages. In addition, it affects the performance of several natural language processing (NLP) task such as machine translation, information retrievals, summarization and etc. In this study, we present an automatic text normalization system on Facebook chatting based on Hausa language. The proposed algorithm manually developed dictionary that employ normalization of each non-standard word with its equivalent standard word. This is accomplished through modification of the technique employed by [1] to fit Hausa NSWs&amp;rsquo; formation. It was found that our proposed algorithm was able to normalized Hausa NSWs with an accuracy of 100%The results of this research can facilitate comprehensive communication via Facebook using Hausa language.&lt;/p&gt;
&lt;style&gt;
body {
text-align: justify}
&lt;/style&gt;
</description>
    </item>
    
    <item>
      <title></title>
      <link>https://hausanlp.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/contact/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://hausanlp.github.io/people/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://hausanlp.github.io/people/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
